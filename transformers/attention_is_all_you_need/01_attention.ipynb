{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iv81o-gVJ5L1"
      },
      "source": [
        "## Single Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5I3D3BYW_Iau"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bbb-vR_t_eR4"
      },
      "outputs": [],
      "source": [
        "def get_input_embeddings(words: List[str], embeddings_dim: int):\n",
        "    # we are creating random vector of embeddings_dim size for each words\n",
        "    # normally we train a tokenizer to get the embeddings.\n",
        "    # check the blog on tokenizer to learn about this part\n",
        "    embeddings = [torch.randn(embeddings_dim) for word in words]\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43QI48Rw_4oH",
        "outputId": "1c10713d-c737-4547-b4b6-cb9ad8800125"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I should sleep now\"\n",
        "words = text.split(\" \")\n",
        "len(words) # 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vTj7ZsMABNS",
        "outputId": "e807f875-aefa-4af2-cba9-042ab8e687ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_dim = 512\n",
        "embeddings = get_input_embeddings(words, embeddings_dim=embeddings_dim)\n",
        "embeddings[0].shape # torch.Size([512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2mTdQRKBSN_",
        "outputId": "83ab4711-c0a4-4870-f88b-eb45d14a6ac9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([512, 512]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initialize the query, key and value metrices\n",
        "query_matrix = nn.Linear(embeddings_dim, embeddings_dim)\n",
        "key_matrix = nn.Linear(embeddings_dim, embeddings_dim)\n",
        "value_matrix = nn.Linear(embeddings_dim, embeddings_dim)\n",
        "query_matrix.weight.shape, key_matrix.weight.shape, value_matrix.weight.shape # torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([512, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8i2IvfOCBk-",
        "outputId": "e2482715-5ff7-4f05-825a-190b811b87cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4, 512]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# query, key and value vectors computation for each words embeddings\n",
        "query_vectors = torch.stack([query_matrix(embedding) for embedding in embeddings])\n",
        "key_vectors = torch.stack([key_matrix(embedding) for embedding in embeddings])\n",
        "value_vectors = torch.stack([value_matrix(embedding) for embedding in embeddings])\n",
        "query_vectors.shape, key_vectors.shape, value_vectors.shape # torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVXRdc0OD0Mn",
        "outputId": "90dbc587-c2a3-4b1b-c643-5f9dad3086b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([512, 4]), torch.Size([512, 4]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "key_vectors.permute(1, 0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6N26GbiDSfK",
        "outputId": "17753259-4b8c-44cc-bdf2-4ee760674339"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compute the score\n",
        "scores = torch.matmul(query_vectors, key_vectors.permute(1, 0)) / torch.sqrt(torch.tensor(embeddings_dim, dtype=torch.float32))\n",
        "scores.shape # torch.Size([4, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0NaMViMEPLg",
        "outputId": "ae87487b-8aaa-4ebf-b117-1ed6499d3eb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compute the attention weights for each of the words with the other words\n",
        "softmax = nn.Softmax(dim=-1)\n",
        "attention_weights = softmax(scores)\n",
        "attention_weights.shape # torch.Size([4, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN0CHYojEd-k",
        "outputId": "4bf30d5a-a96d-4a0a-a4b3-9abac214ef29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 512])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# attention output\n",
        "output = torch.matmul(attention_weights, value_vectors)\n",
        "output.shape # torch.Size([4, 512])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "45sk2I4PJ8_w"
      },
      "source": [
        "## Multi-Head Attention"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zSfLK_ZYKImU"
      },
      "source": [
        "computations are same till query, key and value vector computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iYbY05NCK7Yt"
      },
      "outputs": [],
      "source": [
        "num_heads = 8\n",
        "# batch dim is 1 since we are processing one text.\n",
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvIDez3JJ_V6",
        "outputId": "0ccd1f3a-7cb5-40cc-efed-27900c184144"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"I should sleep now\"\n",
        "words = text.split(\" \")\n",
        "len(words) # 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umBueJ3FKR6M",
        "outputId": "cb8d5d99-fb7d-4f2a-cbf5-472a055fd8c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_dim = 512\n",
        "embeddings = get_input_embeddings(words, embeddings_dim=embeddings_dim)\n",
        "embeddings[0].shape # torch.Size([512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY2TPIvKKTLz",
        "outputId": "19aa912d-dbed-4022-c2f1-da8ec4033a47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([512, 512]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initialize the query, key and value metrices\n",
        "query_matrix = nn.Linear(embeddings_dim, embeddings_dim)\n",
        "key_matrix = nn.Linear(embeddings_dim, embeddings_dim)\n",
        "value_matrix = nn.Linear(embeddings_dim, embeddings_dim)\n",
        "query_matrix.weight.shape, key_matrix.weight.shape, value_matrix.weight.shape # torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([512, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDJFA66EKUQp",
        "outputId": "a043213b-c239-44b9-f2fe-b25b496a70fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4, 512]))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# query, key and value vectors computation for each words embeddings\n",
        "query_vectors = torch.stack([query_matrix(embedding) for embedding in embeddings])\n",
        "key_vectors = torch.stack([key_matrix(embedding) for embedding in embeddings])\n",
        "value_vectors = torch.stack([value_matrix(embedding) for embedding in embeddings])\n",
        "query_vectors.shape, key_vectors.shape, value_vectors.shape # torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDh2T88hKWUq",
        "outputId": "0f7bc79e-817f-40f3-bdaa-9fa21ecd865d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (batch_size, num_heads, seq_len, embeddings_dim)\n",
        "query_vectors_view = query_vectors.view(batch_size, -1, num_heads, embeddings_dim//num_heads).transpose(1, 2)\n",
        "key_vectors_view = key_vectors.view(batch_size, -1, num_heads, embeddings_dim//num_heads).transpose(1, 2)\n",
        "value_vectors_view = value_vectors.view(batch_size, -1, num_heads, embeddings_dim//num_heads).transpose(1, 2)\n",
        "query_vectors_view.shape, key_vectors_view.shape, value_vectors_view.shape\n",
        "# torch.Size([1, 8, 4, 64]),\n",
        "#  torch.Size([1, 8, 4, 64]),\n",
        "#  torch.Size([1, 8, 4, 64])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HKSATdL_OCJT"
      },
      "source": [
        "We are splitting the each vectors into 8 heads. Assuming we have one text (batch size of 1), So we split the embedding vectors also into 8 parts. Each head will take these parts. If we do this one head at a time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMRfCgr-Oran",
        "outputId": "6751b599-8514-4c82-c363-cd3d6794ad32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([4, 64]), torch.Size([4, 64]), torch.Size([4, 64]))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "head1_query_vector = query_vectors_view[0, 0, ...]\n",
        "head1_key_vector = key_vectors_view[0, 0, ...]\n",
        "head1_value_vector = value_vectors_view[0, 0, ...]\n",
        "head1_query_vector.shape, head1_key_vector.shape, head1_value_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yOOb1dMPBpU",
        "outputId": "6420a0f2-9685-4f13-c1a6-775964dbb93d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The above vectors are of same size as before only the feature dim is changed from 512 to 64\n",
        "# compute the score\n",
        "scores_head1 = torch.matmul(head1_query_vector, head1_key_vector.permute(1, 0)) / torch.sqrt(torch.tensor(embeddings_dim//num_heads, dtype=torch.float32))\n",
        "scores_head1.shape # torch.Size([4, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COAMWSCePfjP",
        "outputId": "5767d438-ac2c-4273-d1fd-fe58829ca253"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compute the attention weights for each of the words with the other words\n",
        "softmax = nn.Softmax(dim=-1)\n",
        "attention_weights_head1 = softmax(scores_head1)\n",
        "attention_weights_head1.shape # torch.Size([4, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79EUl5D0PnfE",
        "outputId": "bd8b260b-78d7-487c-be6b-ef4c65cc483d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 64])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_head1 = torch.matmul(attention_weights_head1, head1_value_vector)\n",
        "output_head1.shape # torch.Size([4, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "A66ZIaUdPu5B"
      },
      "outputs": [],
      "source": [
        "# we can compute the output for all the heads\n",
        "outputs = []\n",
        "for head_idx in range(num_heads):\n",
        "    head_idx_query_vector = query_vectors_view[0, head_idx, ...]\n",
        "    head_idx_key_vector = key_vectors_view[0, head_idx, ...]\n",
        "    head_idx_value_vector = value_vectors_view[0, head_idx, ...]\n",
        "    scores_head_idx = torch.matmul(head_idx_query_vector, head_idx_key_vector.permute(1, 0)) / torch.sqrt(torch.tensor(embeddings_dim//num_heads, dtype=torch.float32))\n",
        "\n",
        "    softmax = nn.Softmax(dim=-1)\n",
        "    attention_weights_idx = softmax(scores_head_idx)\n",
        "    output = torch.matmul(attention_weights_idx, head_idx_value_vector)\n",
        "    outputs.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aZB93jRQ63O",
        "outputId": "0acff1e7-6344-49c9-8d84-bfaa12063e4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[torch.Size([4, 64]),\n",
              " torch.Size([4, 64]),\n",
              " torch.Size([4, 64]),\n",
              " torch.Size([4, 64]),\n",
              " torch.Size([4, 64]),\n",
              " torch.Size([4, 64]),\n",
              " torch.Size([4, 64]),\n",
              " torch.Size([4, 64])]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[out.shape for out in outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb-zBR2qRQax",
        "outputId": "e9e28326-e7b4-49fb-ae14-7076c01a0350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stack the result from each heads for the corresponding words\n",
        "word0_outputs = torch.cat([out[0] for out in outputs])\n",
        "word0_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jQhhKDVSCjy",
        "outputId": "08b845dc-b5e1-4d5c-c82a-f629e6ec9e5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[torch.Size([512]), torch.Size([512]), torch.Size([512]), torch.Size([512])]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets do it for all the words\n",
        "attn_outputs = []\n",
        "for i in range(len(words)):\n",
        "    attn_output = torch.cat([out[i] for out in outputs])\n",
        "    attn_outputs.append(attn_output)\n",
        "[attn_output.shape for attn_output in attn_outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5fax7_LSkW7",
        "outputId": "e916e9dd-0dc8-450d-998c-cbc9375fd597"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 64, 4])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now lets do it in vectorize way.\n",
        "# We can not permute the last two dimension of the key vector.\n",
        "key_vectors_view.permute(0, 1, 3, 2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "T8cVkBCcLENs"
      },
      "outputs": [],
      "source": [
        "# Transpose the key vector on the last dim\n",
        "score = torch.matmul(query_vectors_view, key_vectors_view.permute(0, 1, 3, 2)) # Q*k\n",
        "score = torch.softmax(score, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFe9IyaTLo54",
        "outputId": "db36e230-dfef-4f9b-bf80-a46953227d01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reshape the results\n",
        "attention_results = torch.matmul(score, value_vectors_view)\n",
        "attention_results.shape # [1, 8, 4, 64]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybIjnn8xV2tt",
        "outputId": "b535d634-04ac-4081-cd4e-46a428d0fb4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# merge the results\n",
        "attention_results = attention_results.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, embeddings_dim)\n",
        "attention_results.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
